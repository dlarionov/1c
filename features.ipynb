{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f03379ee467570732ebb2b3d20062fea0584d57d"
   },
   "source": [
    "# Part 1, Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('items.csv')\n",
    "shops = pd.read_csv('shops.csv')\n",
    "cats = pd.read_csv('item_categories.csv')\n",
    "train = pd.read_csv('sales_train.csv.gz', compression='gzip')\n",
    "test  = pd.read_csv('test.csv.gz', compression='gzip').set_index('ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed7a190645750a818e29a6291ba2553a91764c7c"
   },
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "425d8f2dc08378977b393bf80c5fdcf0fba2c992"
   },
   "source": [
    "There are items with strange prices and sales. After detailed exploration I decided to remove items with price > 100000 and sales > 1001 (1000 is ok)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a864412fafc3129a3e9bd5bb1f18a7cf0c62935",
    "collapsed": true
   },
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(-100, 3000)\n",
    "sns.boxplot(x=train.item_cnt_day)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(train.item_price.min(), train.item_price.max()*1.1)\n",
    "sns.boxplot(x=train.item_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7e621535d112603c60aeb2c2f83dbbf96d36b732"
   },
   "outputs": [],
   "source": [
    "train = train[train.item_price<100000]\n",
    "train = train[train.item_cnt_day<1001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2f99368478e3063b1c379537944e954d7186928"
   },
   "source": [
    "There is one item with price below zero. Fill it with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0fc6b90b22fe232f4240ac8f965cc52b3db5526a"
   },
   "outputs": [],
   "source": [
    "median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price<0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7da194c285d696b5c6978148bf0143b9b2a7b0c5"
   },
   "source": [
    "Several shops are duplicates of each other (according to its name). Fix train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "00fe91e9c482ea413abd774ff903fe3d152785dd"
   },
   "outputs": [],
   "source": [
    "# Якутск Орджоникидзе, 56\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a30f0521464e1fa20444e66d24bbdcb76b93f6de"
   },
   "source": [
    "## Shops/Cats/Items preprocessing\n",
    "Observations:\n",
    "* Each shop_name starts with the city name.\n",
    "* Each category contains type and subtype in its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "12fae4c8d0c8f3e817307d1e0ffc6831e9a8d696"
   },
   "outputs": [],
   "source": [
    "shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "shops = shops[['shop_id','city_code']]\n",
    "\n",
    "cats['split'] = cats['item_category_name'].str.split('-')\n",
    "cats['type'] = cats['split'].map(lambda x: x[0].strip())\n",
    "cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n",
    "# if subtype is nan then type\n",
    "cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n",
    "cats = cats[['item_category_id','type_code', 'subtype_code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e0da873166e895c2c981a9f38f2647cd3327784"
   },
   "source": [
    "TF-IDF features from item_name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7ec93dbe2c4126e6e8f129d4cd30cebb28ead3bf"
   },
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(TfidfVectorizer(max_features=12).fit_transform(items['item_name']).toarray(), dtype='float16')\n",
    "tfidf.columns = ['tfidf_'+str(id+1) for id in range(12)]\n",
    "tfidf.index.names = ['item_id']\n",
    "tfidf.reset_index(inplace=True)\n",
    "\n",
    "items.drop(['item_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62c5f83fa222595da99294f465ab28e80ce415e9"
   },
   "source": [
    "## Monthly sales\n",
    "Test set is a product of some shops and items within 34 month. There are 5100 items * 42 shops = 214200 pairs. 363 items are new compared to train. Hence, for the most of the items in the test set target value should be zero. \n",
    "In the other hand train set contains only pairs which were sold or returned in the past. Tha main idea is to calculate monthly sales and <b>extend it with zero sales</b> for each unique pair within the month. This way train data will be similar to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fb69350aef2c28cdb619e2532de1e24ab3c43899"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 5100, 214200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(test.item_id) - set(test.item_id).intersection(set(train.item_id)))), len(list(set(test.item_id))), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7626c7455ea71b65894c6c866519df15080fa2ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.66191291809082"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num==i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n",
    "    \n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix['item_id'] = matrix['item_id'].astype(np.int16)\n",
    "matrix.sort_values(cols,inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "867e91a7570dd78b4834f4f1a166e58f80b63f93"
   },
   "source": [
    "Aggregate train set by shop/item pairs to calculate target aggreagates. <b>Clip(0,20) target value.</b>\n",
    "\n",
    "<i>I use floats instead of ints for item_cnt_month and orders to avoid downcasting it after concatination with the test set later. If it would be int16, after concatination with NaN values it becomes int64, but foat16 becomes float16 even with NaNs.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "9fef5477060be7d2e6c85dcb79d8e18e6253f7dd"
   },
   "outputs": [],
   "source": [
    "train['revenue'] = train['item_price'] *  train['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7dd27181918fc7df89676e24d72130d183929d2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.315948247909546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "train_agg = train.groupby(['date_block_num','shop_id','item_id']).agg({\n",
    "    'item_cnt_day': ['sum', 'count'],\n",
    "    'revenue': ['sum']\n",
    "})\n",
    "train_agg.columns = ['item_cnt_month', 'orders', 'revenue']\n",
    "train_agg.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, train_agg, on=cols, how='left')\n",
    "matrix['item_cnt_month'] = (matrix['item_cnt_month']\n",
    "                                .fillna(0)\n",
    "                                .clip(0,20) # NB clip target here\n",
    "                                .astype(np.float16))\n",
    "matrix['orders'] = matrix['orders'].fillna(0).astype(np.float16)\n",
    "matrix['revenue'] = matrix['revenue'].fillna(0).astype(np.float32)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "315bc6107a93f3926a64fd09ea9244e9281ee41f"
   },
   "source": [
    "## Test set\n",
    "To use time tricks append test pairs to the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "29d02bdb4fa768577607bf735b918ca81da85d41"
   },
   "outputs": [],
   "source": [
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "177fbbab94c8057d67d61357d29581248468a74d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2279665470123291"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "matrix = pd.concat([matrix, test], ignore_index=True, keys=cols)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "233e394a6cebf36ef002dc76fef8d430026a52b3"
   },
   "source": [
    "## Shops/Items/Cats features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "7dfd5df3e2bcaee4c312f3979736f52c40f2560f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.23995041847229"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\n",
    "matrix = pd.merge(matrix, items, on=['item_id'], how='left')\n",
    "matrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\n",
    "matrix['city_code'] = matrix['city_code'].astype(np.int8)\n",
    "matrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\n",
    "matrix['type_code'] = matrix['type_code'].astype(np.int8)\n",
    "matrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)\n",
    "matrix.fillna(0, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8358b291fdc8e0e7d1b5700974803b3f104715f7"
   },
   "source": [
    "## Traget lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "9cd7bcc7643ce4545475e8e6f80d09a979aac42d"
   },
   "outputs": [],
   "source": [
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "78bf7ece93ebc4629ad0e48cd6a9927788d8706d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.303950548172"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "matrix = lag_feature(matrix, [1,2,3,4,6,12], 'item_cnt_month')\n",
    "matrix = lag_feature(matrix, [1,2,3], 'orders')\n",
    "matrix = lag_feature(matrix, [1,2,3], 'revenue')\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c67bf4dbcef884ffe9d19c65d37bc4de1f287ef6"
   },
   "source": [
    "## Mean encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "763aca242154ea10fa0a62fffadb4ef90e9532d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.035012006759644"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num']).agg({\n",
    "    'item_cnt_month': ['mean'],\n",
    "    'orders': ['mean'],\n",
    "    'revenue': ['mean'],\n",
    "})\n",
    "group.columns = [ 'date_avg_item_cnt', 'date_avg_orders', 'date_avg_revenue' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\n",
    "matrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_avg_orders'] = matrix['date_avg_orders'].astype(np.float16)\n",
    "matrix['date_avg_revenue'] = matrix['date_avg_revenue'].astype(np.float32)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'date_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1], 'date_avg_orders')\n",
    "matrix = lag_feature(matrix, [1], 'date_avg_revenue')\n",
    "\n",
    "matrix.drop(['date_avg_item_cnt','date_avg_orders','date_avg_revenue'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "fc9166c4e678ebb99d03566f1751b7d4b5c690d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179.89101552963257"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'item_id']).agg({\n",
    "    'item_cnt_month': ['mean' ],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_item_avg_item_cnt', 'date_item_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_item_sum_orders'] = matrix['date_item_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1,2,3,4,6,12], 'date_item_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1,2,3,4,6,12], 'date_item_sum_orders')\n",
    "\n",
    "matrix.drop(['date_item_avg_item_cnt','date_item_sum_orders'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "73f2552c403c5f67bbf07f28d69efcc015d00f32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186.1190049648285"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'shop_id']).agg({\n",
    "    'item_cnt_month': ['mean' ],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_shop_avg_item_cnt', 'date_shop_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_shop_sum_orders'] = matrix['date_shop_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1,2,3,4,6,12], 'date_shop_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1,2,3,4,6,12], 'date_shop_sum_orders')\n",
    "\n",
    "matrix.drop(['date_shop_avg_item_cnt','date_shop_sum_orders'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "c3948a9b206bc480b31385c29a713aa49747de19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.39800071716309"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'item_category_id']).agg({\n",
    "    'item_cnt_month': ['mean'],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_cat_avg_item_cnt', 'date_cat_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\n",
    "matrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_cat_sum_orders'] = matrix['date_cat_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1], 'date_cat_sum_orders')\n",
    "\n",
    "matrix.drop(['date_cat_avg_item_cnt','date_cat_sum_orders'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "bf98335755692f0d7666eeac2db1961692f09a16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.07460403442383"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({\n",
    "    'item_cnt_month': ['mean'],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_shop_cat_avg_item_cnt', 'date_shop_cat_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\n",
    "matrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_shop_cat_sum_orders'] = matrix['date_shop_cat_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_cat_sum_orders')\n",
    "\n",
    "matrix.drop(['date_shop_cat_avg_item_cnt','date_shop_cat_sum_orders'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "87d57d01beb0830138dabae79b4022d4c6a9cc12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.7345016002655"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'city_code']).agg({\n",
    "    'item_cnt_month': ['mean'],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_city_avg_item_cnt', 'date_city_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\n",
    "matrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_city_sum_orders'] = matrix['date_city_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1], 'date_city_sum_orders')\n",
    "\n",
    "matrix.drop(['date_city_avg_item_cnt','date_city_sum_orders'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "db1f0170ec4a6fd9894bc53b36f3166d4b26abcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.05036401748657"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({\n",
    "    'item_cnt_month': ['mean'],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_item_city_avg_item_cnt', 'date_item_city_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\n",
    "matrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_item_city_sum_orders'] = matrix['date_item_city_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1], 'date_item_city_sum_orders')\n",
    "\n",
    "matrix.drop(['date_item_city_avg_item_cnt','date_item_city_sum_orders'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.71849608421326"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'type_code']).agg({\n",
    "    'item_cnt_month': ['mean'],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_type_avg_item_cnt', 'date_type_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\n",
    "matrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_type_sum_orders'] = matrix['date_type_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1], 'date_type_sum_orders')\n",
    "\n",
    "matrix.drop(['date_type_avg_item_cnt','date_type_sum_orders'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.54944252967834"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = matrix.groupby(['date_block_num', 'subtype_code']).agg({\n",
    "    'item_cnt_month': ['mean'],\n",
    "    'orders': ['sum']\n",
    "})\n",
    "group.columns = [ 'date_subtype_avg_item_cnt', 'date_subtype_sum_orders' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\n",
    "matrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix['date_subtype_sum_orders'] = matrix['date_subtype_sum_orders'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\n",
    "matrix = lag_feature(matrix, [1], 'date_subtype_sum_orders')\n",
    "\n",
    "matrix.drop(['date_subtype_avg_item_cnt','date_subtype_sum_orders'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bcea31d93ab035ca3fa1ed7c0afddbf602c414a"
   },
   "source": [
    "## Trend features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0504e9613087237c255914d9ebd165fac4e88cd0"
   },
   "source": [
    "Price trend for the last six months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "0da2ded8502e273137991fd2bebbadaf19c19622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401.1923325061798"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = train.groupby(['item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['item_id'], how='left')\n",
    "matrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "group = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['date_item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "lags = [1,2,3,4,5,6]\n",
    "matrix = lag_feature(matrix, lags, 'date_item_avg_item_price')\n",
    "\n",
    "for i in lags:\n",
    "    matrix['delta_price_lag_'+str(i)] = \\\n",
    "        (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n",
    "\n",
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_price_lag_'+str(i)]:\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0\n",
    "    \n",
    "matrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\n",
    "matrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\n",
    "matrix['delta_price_lag'].fillna(0, inplace=True)\n",
    "\n",
    "# https://stackoverflow.com/questions/31828240/first-non-null-value-per-row-from-a-list-of-pandas-columns/31828559\n",
    "# matrix['price_trend'] = matrix[['delta_price_lag_1','delta_price_lag_2','delta_price_lag_3']].bfill(axis=1).iloc[:, 0]\n",
    "# Invalid dtype for backfill_2d [float16]\n",
    "\n",
    "fetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n",
    "    fetures_to_drop += ['delta_price_lag_'+str(i)]\n",
    "\n",
    "matrix.drop(fetures_to_drop, axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291.65957975387573"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = train.groupby(['shop_id']).agg({'revenue': ['mean']}) #TODO add target mean\n",
    "group.columns = ['shop_avg_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['shop_id'], how='left')\n",
    "matrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float16)\n",
    "\n",
    "group = train.groupby(['date_block_num','shop_id']).agg({'revenue': ['mean']})\n",
    "group.columns = ['date_shop_avg_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_avg_revenue'] = matrix['date_shop_avg_revenue'].astype(np.float16)\n",
    "\n",
    "lags = [1,2,3]\n",
    "matrix = lag_feature(matrix, lags, 'date_shop_avg_revenue')\n",
    "\n",
    "for i in lags:\n",
    "    matrix['delta_revenue_lag_'+str(i)] = \\\n",
    "        (matrix['date_shop_avg_revenue_lag_'+str(i)] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n",
    "\n",
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_revenue_lag_'+str(i)]:\n",
    "            return row['delta_revenue_lag_'+str(i)]\n",
    "    return 0\n",
    "    \n",
    "matrix['delta_revenue_lag'] = matrix.apply(select_trend, axis=1)\n",
    "matrix['delta_revenue_lag'] = matrix['delta_revenue_lag'].astype(np.float16)\n",
    "matrix['delta_revenue_lag'].fillna(0, inplace=True)\n",
    "\n",
    "fetures_to_drop = ['shop_avg_revenue', 'date_shop_avg_revenue']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['date_shop_avg_revenue_lag_'+str(i)]\n",
    "    fetures_to_drop += ['delta_revenue_lag_'+str(i)]\n",
    "\n",
    "matrix.drop(fetures_to_drop, axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47e06af411b7d26cd93dad3d6735e48e5fbdee50"
   },
   "source": [
    "## Special features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc31371e98e4db446dddcd17e13c65d4b3596100"
   },
   "source": [
    "Month (0 - Jan, 11 - Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "bb521e1f33d4124a3b90b47447bdb29150770b6e"
   },
   "outputs": [],
   "source": [
    "matrix['month'] = matrix['date_block_num'] % 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4dc4d2ff86483989c4b74fc02a0d01ca68a5c75"
   },
   "source": [
    "Number of days in a month. There are no leap years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e23f0201056b73368e3b70d4c36c6bb9e4a55291"
   },
   "outputs": [],
   "source": [
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "matrix['days'] = matrix['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c096e86eb0043c0f6eeb899de24e28ca4c4e044"
   },
   "source": [
    "Months since last sale for each shop/item pair and for item only. I use programing approach.\n",
    "\n",
    "Create hash table with key equals to {shop_id,item_id} and value equals to date_block_num. Iterate data from the top. Foreach row if {row.shop_id,item_id} is not present in the table, then add to the table and set its value to row.date_blocl_num. if hash table contains key, then calculate the difference beteween cached value and row.date_block_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "3458a7056c963167760921417d1f863f074f2b39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884.6599349975586"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "cache = {}\n",
    "matrix['item_shop_last_sale'] = -1\n",
    "matrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = str(row.item_id)+' '+str(row.shop_id)\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n",
    "        cache[key] = row.date_block_num         \n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "28b29fae3906d870b4dc3064a7f359b6d3abf623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457.171103477478"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "cache = {}\n",
    "matrix['item_last_sale'] = -1\n",
    "matrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = row.item_id\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if row.date_block_num>last_date_block_num:\n",
    "            matrix.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n",
    "            cache[key] = row.date_block_num         \n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61987e6adc1bec2ea897eec837c0253f7f73fdb5"
   },
   "source": [
    "Months since first sale for each shop/item pair and for item only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "ad0869709bbada35726d5ca41dd913d817249f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8419981002807617"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "matrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "matrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c60aeb05f15e7d9cec69dcc6ccae8fc1f04b5242"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "39820acdd37dc5bf04e7b65b17a1aea1542799e2"
   },
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, tfidf, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "966cb34ccfe849fbb3707d93270691cb8eef7a89"
   },
   "source": [
    "## Final preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee4629c6b8b800679952e8e27f180b3bc0d04899"
   },
   "source": [
    "Because of the using 12 as lag value drop first 12 months. Also drop all the columns with this month calculated values (other words which can not be calcucated for the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "04df1bc4240f409a5d4521c6f70c2ced44f7c3d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.449002981185913"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "matrix = matrix[matrix.date_block_num > 11]\n",
    "matrix.drop(['orders', 'revenue'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48a14784050901f878b40f093e4bc34e07ecce05"
   },
   "source": [
    "Producing lags brings a lot of nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "8e5d8cb5cea9be28af4a0486cc1bf797e5b5c7ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nts = time.time()\\ndef fill_na(df):\\n    for col in df.columns:\\n        if ('_lag_' in col) & (df[col].isnull().any()):\\n            if ('item_cnt' in col):\\n                df[col].fillna(0, inplace=True)\\n            if ('orders' in col):\\n                df[col].fillna(0, inplace=True)\\n            #if ('revenue' in col):\\n            #    df[col].fillna(df[col].median(), inplace=True)            \\n    return df\\n\\nmatrix = fill_na(matrix)\\ntime.time() - ts\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ts = time.time()\n",
    "def fill_na(df):\n",
    "    for col in df.columns:\n",
    "        if ('_lag_' in col) & (df[col].isnull().any()):\n",
    "            if ('item_cnt' in col):\n",
    "                df[col].fillna(0, inplace=True)\n",
    "            if ('orders' in col):\n",
    "                df[col].fillna(0, inplace=True)\n",
    "            #if ('revenue' in col):\n",
    "            #    df[col].fillna(df[col].median(), inplace=True)            \n",
    "    return df\n",
    "\n",
    "matrix = fill_na(matrix)\n",
    "time.time() - ts\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "00bf3fffc1b143d0555d03b9d79b5fd00d9d0dc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'item_cnt_month', 'item_id', 'shop_id', 'city_code',\n",
       "       'item_category_id', 'type_code', 'subtype_code', 'item_cnt_month_lag_1',\n",
       "       'item_cnt_month_lag_2', 'item_cnt_month_lag_3', 'item_cnt_month_lag_4',\n",
       "       'item_cnt_month_lag_6', 'item_cnt_month_lag_12', 'orders_lag_1',\n",
       "       'orders_lag_2', 'orders_lag_3', 'revenue_lag_1', 'revenue_lag_2',\n",
       "       'revenue_lag_3', 'date_avg_item_cnt_lag_1', 'date_avg_orders_lag_1',\n",
       "       'date_avg_revenue_lag_1', 'date_item_avg_item_cnt_lag_1',\n",
       "       'date_item_avg_item_cnt_lag_2', 'date_item_avg_item_cnt_lag_3',\n",
       "       'date_item_avg_item_cnt_lag_4', 'date_item_avg_item_cnt_lag_6',\n",
       "       'date_item_avg_item_cnt_lag_12', 'date_item_sum_orders_lag_1',\n",
       "       'date_item_sum_orders_lag_2', 'date_item_sum_orders_lag_3',\n",
       "       'date_item_sum_orders_lag_4', 'date_item_sum_orders_lag_6',\n",
       "       'date_item_sum_orders_lag_12', 'date_shop_avg_item_cnt_lag_1',\n",
       "       'date_shop_avg_item_cnt_lag_2', 'date_shop_avg_item_cnt_lag_3',\n",
       "       'date_shop_avg_item_cnt_lag_4', 'date_shop_avg_item_cnt_lag_6',\n",
       "       'date_shop_avg_item_cnt_lag_12', 'date_shop_sum_orders_lag_1',\n",
       "       'date_shop_sum_orders_lag_2', 'date_shop_sum_orders_lag_3',\n",
       "       'date_shop_sum_orders_lag_4', 'date_shop_sum_orders_lag_6',\n",
       "       'date_shop_sum_orders_lag_12', 'date_cat_avg_item_cnt_lag_1',\n",
       "       'date_cat_sum_orders_lag_1', 'date_shop_cat_avg_item_cnt_lag_1',\n",
       "       'date_shop_cat_sum_orders_lag_1', 'date_city_avg_item_cnt_lag_1',\n",
       "       'date_city_sum_orders_lag_1', 'date_item_city_avg_item_cnt_lag_1',\n",
       "       'date_item_city_sum_orders_lag_1', 'date_type_avg_item_cnt_lag_1',\n",
       "       'date_type_sum_orders_lag_1', 'date_subtype_avg_item_cnt_lag_1',\n",
       "       'date_subtype_sum_orders_lag_1', 'delta_price_lag', 'delta_revenue_lag',\n",
       "       'month', 'days', 'item_shop_last_sale', 'item_last_sale',\n",
       "       'item_shop_first_sale', 'item_first_sale', 'tfidf_1', 'tfidf_2',\n",
       "       'tfidf_3', 'tfidf_4', 'tfidf_5', 'tfidf_6', 'tfidf_7', 'tfidf_8',\n",
       "       'tfidf_9', 'tfidf_10', 'tfidf_11', 'tfidf_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "5d9988f8da8876f74092fbf827ceb6c61dd09d5e"
   },
   "outputs": [],
   "source": [
    "matrix.to_pickle('matrix.pkl')\n",
    "# matrix = pickle.load(open('matrix.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6639294 entries, 4488710 to 11128003\n",
      "Data columns (total 79 columns):\n",
      "date_block_num                       int8\n",
      "item_cnt_month                       float16\n",
      "item_id                              int16\n",
      "shop_id                              int8\n",
      "city_code                            int8\n",
      "item_category_id                     int8\n",
      "type_code                            int8\n",
      "subtype_code                         int8\n",
      "item_cnt_month_lag_1                 float16\n",
      "item_cnt_month_lag_2                 float16\n",
      "item_cnt_month_lag_3                 float16\n",
      "item_cnt_month_lag_4                 float16\n",
      "item_cnt_month_lag_6                 float16\n",
      "item_cnt_month_lag_12                float16\n",
      "orders_lag_1                         float16\n",
      "orders_lag_2                         float16\n",
      "orders_lag_3                         float16\n",
      "revenue_lag_1                        float32\n",
      "revenue_lag_2                        float32\n",
      "revenue_lag_3                        float32\n",
      "date_avg_item_cnt_lag_1              float16\n",
      "date_avg_orders_lag_1                float16\n",
      "date_avg_revenue_lag_1               float32\n",
      "date_item_avg_item_cnt_lag_1         float16\n",
      "date_item_avg_item_cnt_lag_2         float16\n",
      "date_item_avg_item_cnt_lag_3         float16\n",
      "date_item_avg_item_cnt_lag_4         float16\n",
      "date_item_avg_item_cnt_lag_6         float16\n",
      "date_item_avg_item_cnt_lag_12        float16\n",
      "date_item_sum_orders_lag_1           float16\n",
      "date_item_sum_orders_lag_2           float16\n",
      "date_item_sum_orders_lag_3           float16\n",
      "date_item_sum_orders_lag_4           float16\n",
      "date_item_sum_orders_lag_6           float16\n",
      "date_item_sum_orders_lag_12          float16\n",
      "date_shop_avg_item_cnt_lag_1         float16\n",
      "date_shop_avg_item_cnt_lag_2         float16\n",
      "date_shop_avg_item_cnt_lag_3         float16\n",
      "date_shop_avg_item_cnt_lag_4         float16\n",
      "date_shop_avg_item_cnt_lag_6         float16\n",
      "date_shop_avg_item_cnt_lag_12        float16\n",
      "date_shop_sum_orders_lag_1           float16\n",
      "date_shop_sum_orders_lag_2           float16\n",
      "date_shop_sum_orders_lag_3           float16\n",
      "date_shop_sum_orders_lag_4           float16\n",
      "date_shop_sum_orders_lag_6           float16\n",
      "date_shop_sum_orders_lag_12          float16\n",
      "date_cat_avg_item_cnt_lag_1          float16\n",
      "date_cat_sum_orders_lag_1            float16\n",
      "date_shop_cat_avg_item_cnt_lag_1     float16\n",
      "date_shop_cat_sum_orders_lag_1       float16\n",
      "date_city_avg_item_cnt_lag_1         float16\n",
      "date_city_sum_orders_lag_1           float16\n",
      "date_item_city_avg_item_cnt_lag_1    float16\n",
      "date_item_city_sum_orders_lag_1      float16\n",
      "date_type_avg_item_cnt_lag_1         float16\n",
      "date_type_sum_orders_lag_1           float16\n",
      "date_subtype_avg_item_cnt_lag_1      float16\n",
      "date_subtype_sum_orders_lag_1        float16\n",
      "delta_price_lag                      float16\n",
      "delta_revenue_lag                    float16\n",
      "month                                int8\n",
      "days                                 int8\n",
      "item_shop_last_sale                  int8\n",
      "item_last_sale                       int8\n",
      "item_shop_first_sale                 int8\n",
      "item_first_sale                      int8\n",
      "tfidf_1                              float16\n",
      "tfidf_2                              float16\n",
      "tfidf_3                              float16\n",
      "tfidf_4                              float16\n",
      "tfidf_5                              float16\n",
      "tfidf_6                              float16\n",
      "tfidf_7                              float16\n",
      "tfidf_8                              float16\n",
      "tfidf_9                              float16\n",
      "tfidf_10                             float16\n",
      "tfidf_11                             float16\n",
      "tfidf_12                             float16\n",
      "dtypes: float16(62), float32(4), int16(1), int8(12)\n",
      "memory usage: 1.0 GB\n"
     ]
    }
   ],
   "source": [
    "matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
